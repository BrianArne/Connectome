{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from __future__ import print_function\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Connectome data, convert into feature vectors and mComp2 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading Data, return X and Y\n",
    "\n",
    "def load_data_noPreprocessing_MS2(normalize = False):\n",
    "    m = scipy.io.loadmat(\"F.mat\")\n",
    "    m = scipy.io.loadmat(\"/data/eric/UNC/work/F.mat\")\n",
    "\n",
    "    y = []\n",
    "    X = []\n",
    "\n",
    "    for i in range(len(m['F'][0])):\n",
    "        connectome = m['F'][0,i][0][0][22]\n",
    "        group = m['F'][0,i][0][0][23]\n",
    "        #change to 23 to return binary values of MS score. (21 for ranged values, 25 for 3bins)\n",
    "\n",
    "        X.append( np.array( connectome )[0] )\n",
    "        y.append( group[0,0] )\n",
    "        \n",
    "    if (normalize):\n",
    "        #now, normalize the x data:\n",
    "        print(\"normalizing data\")\n",
    "        for i in range(len(X)):\n",
    "            maxX = max(X[i])\n",
    "            for j in range(len(X[i])):\n",
    "                X[i][j] = X[i][j] / maxX\n",
    "        \n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search Function to find best possible parameters of computer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grid search to find best alpha and l1ratio:\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "X,y = load_data_noPreprocessing_MS2()\n",
    "\n",
    "\n",
    "bestDifference = 100\n",
    "bestCombo = \"\"\n",
    "\n",
    "#Create the gridsearch of a's and l1's:\n",
    "for a in range(20):\n",
    "    allCVals = []\n",
    "    for b in range(3):#rerun the same C val multiple times\n",
    "        cval = a *3+1\n",
    "\n",
    "        fold = 1\n",
    "        #Kfold Loop:\n",
    "        kfoldDiff = []\n",
    "        kf = KFold(n_splits=10,shuffle=True)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            fold += 1\n",
    "\n",
    "            #Create the test and training data:\n",
    "            xTrain = []\n",
    "            yTrain = []\n",
    "            xTest = []\n",
    "            yTest = []\n",
    "\n",
    "            #Fill in the test and training data.\n",
    "            for i in range(len(train_index)):\n",
    "                xTrain.append(X[train_index[i]])\n",
    "                yTrain.append(y[train_index[i]])\n",
    "\n",
    "            for i in range(len(test_index)):\n",
    "                xTest.append(X[test_index[i]])\n",
    "                yTest.append(y[test_index[i]])   \n",
    "\n",
    "            #Create the model based on the grid values for alpha and l1\n",
    "            predictor = RandomForestRegressor(n_estimators=10, min_samples_split = 0.35)\n",
    "            predictor.fit(xTrain, yTrain)\n",
    "\n",
    "            diffs = []\n",
    "            for i in range(len(xTest)):\n",
    "                prediction = predictor.predict([xTest[i]])[0]\n",
    "                diff = abs(yTest[i] - prediction)\n",
    "                \n",
    "                if prediction > yTest[i]:\n",
    "                    diff = prediction - yTest[i]\n",
    "                else: diff = yTest[i] - prediction\n",
    "                \n",
    "                diffs.append(diff)\n",
    "                kfoldDiff.append(diff)\n",
    "\n",
    "        print(\"Change value\",cval,\"run number:\",b,\"KFold diff:\",np.mean(kfoldDiff))\n",
    "        if (np.mean(kfoldDiff) < bestDifference):\n",
    "            bestDifference = np.mean(kfoldDiff)\n",
    "            bestCombo = \"a:\" + str(cval)\n",
    "        allCVals.append(np.mean(kfoldDiff))\n",
    "    print(\"Average diff:\",np.mean(allCVals),\"\\n\")\n",
    "    \n",
    "print(\"\\n\\nFinal Results:\\nY value standard deviation:\",np.std(y))\n",
    "print(\"bestDiff:\",bestDifference, \"\\n\", \"Best combo:\", bestCombo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Model for MComp2 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##MCOMP2CLASSIFICATION\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import *\n",
    "from sklearn.tree import *\n",
    "import random\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "X,y = load_data_noPreprocessing_MS2()\n",
    "\n",
    "def run(times,show):\n",
    "    allAcc = []\n",
    "    allRandAcc = []\n",
    "    for t in range(times):\n",
    "        fold = 1\n",
    "        #Kfold Loop:\n",
    "\n",
    "        kfoldDiff = []\n",
    "        kfoldFixDiff = []\n",
    "        histData = []\n",
    "        coefSum = [0] * len(X[0])\n",
    "\n",
    "        accuracy = []#only add in 1 for correct, 0 for incorrect.\n",
    "        randAccuracy = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            if show:print(\"Fold:\",fold,\"\\nPred\\tActual\\tPred diff\\tfixed Diff\")\n",
    "            fold += 1\n",
    "\n",
    "            #Create the test and training data:\n",
    "            xTrain = []\n",
    "            yTrain = []\n",
    "            xTest = []\n",
    "            yTest = []\n",
    "\n",
    "            #Fill in the test and training data.\n",
    "            for i in range(len(train_index)):\n",
    "                xTrain.append(X[train_index[i]])\n",
    "                yTrain.append(y[train_index[i]])\n",
    "\n",
    "            for i in range(len(test_index)):\n",
    "                xTest.append(X[test_index[i]])\n",
    "                yTest.append(y[test_index[i]])   \n",
    "\n",
    "\n",
    "            #Define the model:\n",
    "            ##predictor = ElasticNet(alpha=0.25, l1_ratio=0.35)\n",
    "            #predictor = svm.SVC(C=0.8)\n",
    "            ##predictor = ElasticNet(alpha=0.25, l1_ratio=0.45)\n",
    "            ##predictor = svm.LinearSVC(C=0.9)\n",
    "            ##predictor = svm.LinearSVC(C=0.01)s\n",
    "            predictor = LinearRegression()\n",
    "            ##predictor = ExtraTreeClassifier()\n",
    "            ##predictor = RandomForestRegressor(n_estimators=10, min_samples_split = 0.35)\n",
    "            ##predictor = Lasso(alpha=0.45)\n",
    "            ####predictor = DecisionTreeRegressor(random_state=0)\n",
    "            ##predictor = MLPClassifier(solver='lbfgs', alpha=0.7,\n",
    "            ##                hidden_layer_sizes=(len(xTrain),len(xTrain),len(xTrain)), random_state=1)\n",
    "            predictor.fit(xTrain, yTrain)\n",
    "\n",
    "\n",
    "            diffs = []\n",
    "            fixDiffs = []\n",
    "            for i in range(len(xTest)):\n",
    "                #Create a fixed pred that always guesses the average value of training Y.\n",
    "                fixedPred = int(np.median(yTrain))\n",
    "                fixedPred = random.choice(yTrain)\n",
    "\n",
    "                prediction = round(predictor.predict([xTest[i]])[0])\n",
    "                histData.append(yTest[i] - prediction)\n",
    "                diff = abs(yTest[i] - prediction)\n",
    "\n",
    "                if prediction > yTest[i]:\n",
    "                    diff = prediction - yTest[i]\n",
    "                else: diff = yTest[i] - prediction\n",
    "\n",
    "                #Collect accuracy:\n",
    "                if diff == 0:\n",
    "                    accuracy.append(1)\n",
    "                else: accuracy.append(0)\n",
    "\n",
    "                if fixedPred > yTest[i]:\n",
    "                    fixDiff = fixedPred - yTest[i]\n",
    "                else: fixDiff = yTest[i] - fixedPred\n",
    "\n",
    "                if fixedPred == yTest[i]:\n",
    "                    randAccuracy.append(1)\n",
    "                else: randAccuracy.append(0)\n",
    "\n",
    "                if show: print(int(prediction),\"\\t\",yTest[i], \"\\tDiff:\",int(diff),\"\\t\",(fixDiff))\n",
    "                diffs.append(diff)\n",
    "                kfoldDiff.append(diff)\n",
    "                fixDiffs.append(fixDiff)\n",
    "                kfoldFixDiff.append(fixDiff)\n",
    "\n",
    "            if show:print(\"Accuracy:\",1.0 - float(sum(diffs)) / float(len(diffs)))\n",
    "            if show:print(\"Differences:\",float(sum(diffs)) / float(len(diffs)))\n",
    "        \n",
    "        if show:print(\"KFold prediction Difference:\",(np.mean(kfoldDiff)),\"\\tkfold random Difference:\",(np.mean(kfoldFixDiff)))\n",
    "        if show:print(\"Y value standard deviation:\",np.std(y))\n",
    "\n",
    "        if show:print(\"\\n\\nChance to guess correct bin:\",np.mean(accuracy))\n",
    "        if show:print(\"Random chance to guess correct bin:\",np.mean(randAccuracy))\n",
    "        allAcc.append(np.mean(accuracy))\n",
    "        allRandAcc.append(np.mean(randAccuracy))\n",
    "        print(t,\",\",end=\"\")\n",
    "    print(\"\\nAll Accuracy:\",np.mean(allAcc))\n",
    "    print(\"Rand Accuracy:\",np.mean(allRandAcc))\n",
    "    \n",
    "run(200,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive model for Mcomp2 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##MCOMP2 SCORE PREDICTIONS\n",
    "from sklearn.neural_network import *\n",
    "from random import *\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "\n",
    "def getData(normalize = False):\n",
    "    m = scipy.io.loadmat(\"F.mat\")\n",
    "    m = scipy.io.loadmat(\"/data/eric/UNC/work/F.mat\")\n",
    "\n",
    "    y = []\n",
    "    X = []\n",
    "    groups = []\n",
    "    for i in range(len(m['F'][0])):\n",
    "        connectome = m['F'][0,i][0][0][22]\n",
    "        group = m['F'][0,i][0][0][21]\n",
    "        typeGroup = m['F'][0,i][0][0][6][0]\n",
    "        #change to 23 to return binary values of MS score. (21 for ranged values, 25 for 3bins)\n",
    "\n",
    "        X.append( np.array( connectome )[0] )\n",
    "        y.append( group[0,0] )\n",
    "        groups.append(typeGroup)\n",
    "        \n",
    "    if (normalize):\n",
    "        #now, normalize the x data:\n",
    "        print(\"normalizing data\")\n",
    "        for i in range(len(X)):\n",
    "            maxX = max(X[i])\n",
    "            for j in range(len(X[i])):\n",
    "                X[i][j] = X[i][j] / maxX\n",
    "        \n",
    "        \n",
    "    return X, y, groups\n",
    "   \n",
    "\n",
    "#Execute this function\n",
    "def run(algo,show=True,updatedFold=False):\n",
    "    X,y,groups = getData()\n",
    "    kf = KFold(n_splits=10,shuffle=True)\n",
    "    \n",
    "    fold = 0\n",
    "    \n",
    "    singletonDiffs = []\n",
    "    twinDiffs = []\n",
    "    riskDiffs = []\n",
    "    allDiffs = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "            fold += 1\n",
    "            if show:print(\"\\nFold:\",fold,\"\\nActual\\tPredicted\\tDifference\\tGroup\")\n",
    "            \n",
    "            #Create the test and training data:\n",
    "            xTrain = []\n",
    "            yTrain = []\n",
    "            xTest = []\n",
    "            yTest = []\n",
    "            groupTrain = []\n",
    "            groupTest = []\n",
    "        \n",
    "            if updatedFold:#fill in training data with updated algo.\n",
    "                testIndexes = updatedIndexPicker()\n",
    "                thisTestIndexes = testIndexes[fold-1]\n",
    "                \n",
    "                #Iterate through X.  If the current index is in the fold's\n",
    "                #test values, add that X index to xTest.  Same for Y and group.\n",
    "                for i in range(len(X)):\n",
    "                    if i in thisTestIndexes:\n",
    "                        xTest.append(X[i])\n",
    "                        yTest.append(y[i])   \n",
    "                        groupTest.append(groups[i])\n",
    "                    else:\n",
    "                        xTrain.append(X[i])\n",
    "                        yTrain.append(y[i])\n",
    "                        groupTrain.append(groups[i])\n",
    "                shuffle(yTrain)\n",
    "            else:\n",
    "                #Fill in the test and training data.\n",
    "                for i in range(len(train_index)):\n",
    "                    xTrain.append(X[train_index[i]])\n",
    "                    yTrain.append(y[train_index[i]])\n",
    "                    groupTrain.append(groups[train_index[i]])\n",
    "\n",
    "                for i in range(len(test_index)):\n",
    "                    xTest.append(X[test_index[i]])\n",
    "                    yTest.append(y[test_index[i]])   \n",
    "                    groupTest.append(groups[test_index[i]])\n",
    "                \n",
    "                \n",
    "            #Define the model:\n",
    "            algos = [ElasticNet(alpha=0.25, l1_ratio=0.45),\n",
    "                     LinearRegression(),\n",
    "                     RandomForestRegressor(n_estimators=10, min_samples_split = 0.35),\n",
    "                     Lasso(alpha=0.45),\n",
    "                     DecisionTreeRegressor(random_state=0)]\n",
    "            predictor = algos[algo]\n",
    "            \n",
    "            predictor.fit(xTrain, yTrain)\n",
    "\n",
    "\n",
    "            diffs = []\n",
    "            #make predictions for every test index\n",
    "            for i in range(len(xTest)):\n",
    "                #Create a fixed pred that always guesses the average value of training Y.\n",
    "                prediction = (predictor.predict([xTest[i]])[0])\n",
    "                diff = abs(yTest[i] - prediction)\n",
    "                if show:print(yTest[i],\"\\t\",\"%0.3f\"%prediction,\"\\t\",\"%0.2f\"%diff,\"\\t\\t\",groupTest[i])\n",
    "                #print(groupTest[i][0])\n",
    "                \n",
    "                #Now, add the differences to each of the groups:\n",
    "                if (groupTest[i][0] == \"S\"):\n",
    "                    singletonDiffs.append(diff)\n",
    "                elif (groupTest[i][0] == \"T\"):\n",
    "                    twinDiffs.append(diff)\n",
    "                else:\n",
    "                    riskDiffs.append(diff)\n",
    "                allDiffs.append(diff)\n",
    "                \n",
    "    if show:print(\"\\nSingleton difference:\",np.mean(singletonDiffs))\n",
    "    if show:print(\"Twin difference:\",np.mean(twinDiffs))\n",
    "    if show:print(\"High Risk difference:\",np.mean(riskDiffs))\n",
    "    if show:print(\"Average difference:\",np.mean(allDiffs))\n",
    "    if show:print(\"Standard dev:\",np.std(allDiffs))#about 7-9\n",
    "    \n",
    "    return np.mean(singletonDiffs),np.mean(twinDiffs),np.mean(riskDiffs),np.mean(allDiffs)\n",
    "\n",
    "\n",
    "def runTimes(algo,times):\n",
    "    allSingDiffs = []\n",
    "    allTwinDiffs = []\n",
    "    allRiskDiffs = []\n",
    "    allAllDiffs = []\n",
    "    \n",
    "    for i in range(times):\n",
    "        print(\".\",end=\"\",sep=\"\")\n",
    "        sing,twin,risk,allD = run(algo,show=False,updatedFold=True)\n",
    "        allSingDiffs.append(sing)\n",
    "        allTwinDiffs.append(twin)\n",
    "        allRiskDiffs.append(risk)\n",
    "        allAllDiffs.append(allD)\n",
    "    print(\"\\n\\nAverage Singleton Difference:\",np.mean(allSingDiffs))\n",
    "    print(\"Average Twin Difference:\",np.mean(allTwinDiffs))\n",
    "    print(\"Average High Risk Difference:\",np.mean(allRiskDiffs))\n",
    "    print(\"Average All Difference:\",np.mean(allAllDiffs))\n",
    "\n",
    "\n",
    "#Run all of the algorithms\n",
    "print(\"Elastic net:\")\n",
    "runTimes(0,30)\n",
    "\n",
    "print(\"\\n\\nLinear Regression:\")\n",
    "runTimes(1,30)\n",
    "\n",
    "print(\"\\n\\nRandom Forest Regressor:\")\n",
    "runTimes(2,30)\n",
    "\n",
    "print(\"\\n\\nLasso:\")\n",
    "runTimes(3,50)\n",
    "\n",
    "print(\"\\n\\nDecision Tree Regressor:\")\n",
    "runTimes(4,30)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the neural network data.  First, read the output file and parse into usable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "def load_data_noPreprocessing_MS2(lay1Len,lay2Len,lay3Len,lay4Len):\n",
    "    m = io.loadmat(\"T.mat\")\n",
    "\n",
    "    y = []\n",
    "    X = []\n",
    "\n",
    "    layers = [[],[],[],[],[]]\n",
    "    \n",
    "    #set up the layer combos\n",
    "    for i in range(lay1Len):\n",
    "        layers[0].append([1000])\n",
    "    for i in range(lay2Len):\n",
    "        layers[1].append([2000])\n",
    "    for i in range(lay3Len):\n",
    "        layers[2].append([3000])\n",
    "    for i in range(lay4Len):\n",
    "        layers[3].append([4000])\n",
    "    for i in range(300):\n",
    "        layers[4].append([5000])\n",
    "    \n",
    "    \n",
    "    for i in range(len(m['T'][0])):\n",
    "        theseInodes = m['T'][0][i][0][0][2]\n",
    "        position = m['T'][0][i][0][0][1][0][0]\n",
    "        thisLayer = m['T'][0][i][0][0][0][0][0]\n",
    "        newInodes = []\n",
    "        for j in range(len(theseInodes)):\n",
    "            newInodes.append(theseInodes[j][0])\n",
    "\n",
    "        layers[thisLayer-1][position-1] = newInodes\n",
    "\n",
    "    return layers\n",
    "    \n",
    "layers = load_data_noPreprocessing_MS2(4,6,11,50)   \n",
    "\n",
    "\n",
    "allPaths = []\n",
    "counter = 1\n",
    "def getChildren(path,index,currentLayer,layers):\n",
    "    if (index>= len(layers[currentLayer])): return\n",
    "    inodes = layers[currentLayer][index]\n",
    "    \n",
    "    if currentLayer == 4  and max(inodes) < 500:\n",
    "        paths = []\n",
    "        for i in range(len(inodes)):\n",
    "            thisPath = path[:]\n",
    "            thisPath.append(inodes[i])\n",
    "            \n",
    "            allPaths.append(thisPath)\n",
    "            print(\"\\t\\t\\t\\tPATH\",thisPath)\n",
    "    #otherwise, continue to the next layer:\n",
    "    else:\n",
    "        if currentLayer == 0 and max(inodes) < 500:\n",
    "            print(\"firstlayer:\",index+1,inodes)\n",
    "        if currentLayer == 1 and max(inodes) < 500:\n",
    "            print(\"\\tsecondlayer:\",index+1,inodes)\n",
    "        if currentLayer == 2 and max(inodes) < 500:\n",
    "            print(\"\\t\\tthirdlayer:\",index+1,inodes)\n",
    "        if currentLayer == 3 and max(inodes) < 500:\n",
    "            print(\"\\t\\t\\tfourthlayer:\",index+1,inodes)\n",
    "        for i in range(len(inodes)):\n",
    "            if inodes[i] < 500:\n",
    "                newPath = path[:]\n",
    "                newPath.append(inodes[i])\n",
    "                getChildren(newPath,inodes[i]-1,currentLayer +1,layers)\n",
    " \n",
    "getChildren([1],0,0,layers)\n",
    "getChildren([2],1,0,layers)\n",
    "getChildren([3],2,0,layers)\n",
    "getChildren([4],3,0,layers)\n",
    "\n",
    "for i in range(len(allPaths)):\n",
    "    print(\"Path\",i,allPaths[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the parsed data to draw to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.drawing.nx_pylab.draw_networkx.html\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "     \n",
    "def main():\n",
    "    \n",
    "    connections = []\n",
    "    for i in range(len(allPaths)):\n",
    "        #Add in all of the nodes:\n",
    "        connections.append((\"\"+ str(allPaths[i][0]) + \"\",\" \"+str(allPaths[i][1])+ \" \" ))\n",
    "        connections.append((\" \"+ str(allPaths[i][1]) + \" \",\"  \"+str(allPaths[i][2])+ \"  \" ))\n",
    "        connections.append((\"  \"+ str(allPaths[i][2]) + \"  \",\"   \"+str(allPaths[i][3])+ \"   \" ))\n",
    "        connections.append((\"   \"+ str(allPaths[i][3]) + \"   \",\"    \"+str(allPaths[i][4])+ \"    \" ))\n",
    "        connections.append((\"    \"+ str(allPaths[i][4]) + \"    \",\"     \"+str(allPaths[i][5])+ \"     \" ))\n",
    "        \n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "    l = connections\n",
    "     \n",
    "    # Build up a graph\n",
    "    for t in l:\n",
    "        G.add_edge(t[0], t[1])\n",
    "     \n",
    "    # Plot trees\n",
    "    pos=graphviz_layout(G, prog='dot')\n",
    "    nx.draw_networkx(G, pos, with_labels=True, arrows=False,node_size=350,node_shape='s',node_color=\"#aef2c6\")\n",
    "    plt.savefig('draw_trees_with_pygraphviz.png', bbox_inches='tight')   \n",
    "    plt.show()\n",
    "     \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
